import { GoogleGenAI, Part, Content, Chat, Type, FunctionDeclaration, Session, LiveServerMessage, Modality, Blob } from "@google/genai";
import { ChatMessage, GeneratedReportData, Report, Theme, UserProfile, LegalAssistantResponse, StoredDocument, StructuredLegalDocument, View } from '../types';
import { SYSTEM_PROMPT_CHAT, SYSTEM_PROMPT_REPORT_GENERATION, SYSTEM_PROMPT_THEME_ANALYSIS, SYSTEM_PROMPT_VOICE_AGENT } from '../constants';
import { SYSTEM_PROMPT_SINGLE_INCIDENT_ANALYSIS } from '../constants/behavioralPrompts';
import { SYSTEM_PROMPT_LEGAL_ASSISTANT, SYSTEM_PROMPT_LEGAL_ANALYSIS_SUGGESTION, SYSTEM_PROMPT_DOCUMENT_ANALYSIS, SYSTEM_PROMPT_DOCUMENT_REDRAFT, SYSTEM_PROMPT_EVIDENCE_PACKAGE } from '../constants/legalPrompts';
import { INDIANA_LEGAL_CONTEXT } from "../constants/legalContext";

const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

// Schemas for structured JSON responses
const reportResponseSchema = {
    type: Type.OBJECT,
    properties: {
        content: {
            type: Type.STRING,
            description: "A detailed, neutral summary of the incident in Markdown format, with specific headings."
        },
        category: {
            type: Type.STRING,
            description: "The single most appropriate category for the incident."
        },
        tags: {
            type: Type.ARRAY,
            items: {
                type: Type.STRING
            },
            description: "An array of 3-5 relevant keywords as tags."
        },
        legalContext: {
            type: Type.STRING,
            description: "An optional, neutral sentence connecting the incident to a principle from Indiana law. Omit if not applicable."
        }
    },
    required: ['content', 'category', 'tags']
};

const themeAnalysisSchema = {
    type: Type.ARRAY,
    items: {
        type: Type.OBJECT,
        properties: {
            name: {
                type: Type.STRING,
                description: "The specific, concrete behavioral theme identified."
            },
            value: {
                type: Type.NUMBER,
                description: "The number of reports that mention this theme."
            }
        },
        required: ['name', 'value']
    }
};

const structuredLegalDocumentSchema = {
    type: Type.OBJECT,
    properties: {
        title: { type: Type.STRING, description: "The main title of the document." },
        subtitle: { type: Type.STRING, description: "An optional subtitle." },
        metadata: {
            type: Type.OBJECT,
            properties: {
                date: { type: Type.STRING, description: "The date in YYYY-MM-DD format." },
                clientName: { type: Type.STRING, description: "The client's name, if applicable." },
                caseNumber: { type: Type.STRING, description: "The case number, if applicable." }
            },
            required: ['date']
        },
        preamble: { type: Type.STRING, description: "The introductory paragraph or preamble." },
        sections: {
            type: Type.ARRAY,
            items: {
                type: Type.OBJECT,
                properties: {
                    heading: { type: Type.STRING, description: "The heading of the section." },
                    body: { type: Type.STRING, description: "The body content of the section, with newlines for paragraphs." }
                },
                required: ['heading', 'body']
            }
        },
        closing: { type: Type.STRING, description: "The closing text before signatures." },
        notes: { type: Type.STRING, description: "Optional notes at the end of the document." }
    },
    required: ['title', 'metadata', 'preamble', 'sections', 'closing']
};

const formatUserProfileContext = (profile: UserProfile | null): string => {
    if (!profile || !profile.name) return '';
    
    let context = `The user's name is ${profile.name}`;
    if (profile.role) {
        context += `, and they identify as the ${profile.role}. The other parent should be referred to as the ${profile.role === 'Mother' ? 'Father' : 'Mother'}.`;
    }
    if (profile.children && profile.children.length > 0) {
        context += ` The child/children involved are: ${profile.children.join(', ')}.`;
    }
    return `\n### User Context\n${context}\n`;
}

const formatMessagesToContent = (messages: ChatMessage[]): Content[] => {
    return messages.map(msg => {
        const parts: Part[] = [{ text: msg.content }];
        if (msg.images) {
            msg.images.forEach(image => {
                parts.push({
                    inlineData: {
                        mimeType: image.mimeType,
                        data: image.data,
                    },
                });
            });
        }
        return {
            role: msg.role,
            parts,
        };
    });
};

export const getChatResponse = async (messages: ChatMessage[], userProfile: UserProfile | null): Promise<{ text: string; tokensUsed: number }> => {
    const contents = formatMessagesToContent(messages);
    const systemInstruction = SYSTEM_PROMPT_CHAT.replace('{USER_PROFILE_CONTEXT}', formatUserProfileContext(userProfile));

    const response = await ai.models.generateContent({
        model: 'gemini-2.5-flash',
        contents: contents,
        config: {
            systemInstruction: systemInstruction,
        }
    });

    const tokensUsed = response.usageMetadata?.totalTokenCount ?? 0;
    return { text: response.text, tokensUsed };
};

export const generateJsonReport = async (messages: ChatMessage[], userProfile: UserProfile | null): Promise<{ reportData: GeneratedReportData | null; tokensUsed: number }> => {
    const conversationText = messages
        .map(m => `${m.role === 'user' ? 'User' : 'Assistant'}: ${m.content}`)
        .join('\n\n');
    
    const userPrompt = `Based on the conversation transcript provided below, please generate the incident report JSON.\n\n--- CONVERSATION START ---\n\n${conversationText}\n\n--- CONVERSATION END ---`;
    
    const systemInstruction = SYSTEM_PROMPT_REPORT_GENERATION.replace('{USER_PROFILE_CONTEXT}', formatUserProfileContext(userProfile));

    try {
        const response = await ai.models.generateContent({
            model: 'gemini-2.5-flash',
            contents: userPrompt,
            config: {
                systemInstruction: systemInstruction,
                responseMimeType: "application/json",
                responseSchema: reportResponseSchema,
            }
        });

        const tokensUsed = response.usageMetadata?.totalTokenCount ?? 0;
        const jsonText = response.text.trim();
        
        if (!jsonText) {
            console.error("Received empty response from report generation.");
            return { reportData: null, tokensUsed };
        }

        const reportData = JSON.parse(jsonText);
        
        if (reportData.content && reportData.category && reportData.tags) {
            return { reportData: reportData as GeneratedReportData, tokensUsed };
        }
        return { reportData: null, tokensUsed };
    } catch (e) {
        console.error("Failed to generate or parse report JSON:", e);
        return { reportData: null, tokensUsed: 0 };
    }
};

export const getThemeAnalysis = async (reports: Report[], category: string): Promise<{ themes: Theme[]; tokensUsed: number }> => {
    const reportsContent = reports.map(r => `--- REPORT ---\n${r.content}\n--- END REPORT ---`).join('\n\n');
    const prompt = SYSTEM_PROMPT_THEME_ANALYSIS.replace('{CATEGORY_NAME}', category);

    try {
        const response = await ai.models.generateContent({
            model: 'gemini-2.5-flash',
            contents: `${prompt}\n\n## Incident Reports Content\n\n${reportsContent}`,
            config: {
                responseMimeType: "application/json",
                responseSchema: themeAnalysisSchema,
            }
        });
        
        const tokensUsed = response.usageMetadata?.totalTokenCount ?? 0;
        const jsonText = response.text.trim();
        const themes = JSON.parse(jsonText);
        if (Array.isArray(themes)) {
            return { themes: themes as Theme[], tokensUsed };
        }
        return { themes: [], tokensUsed };
    } catch (e) {
        console.error("Failed to get theme analysis:", e);
        return { themes: [], tokensUsed: 0 };
    }
};

export const getSingleIncidentAnalysis = async (mainReport: Report, allReports: Report[], userProfile: UserProfile | null): Promise<{ analysis: string; sources: any[]; tokensUsed: number }> => {
    const mainReportContent = `--- PRIMARY INCIDENT TO ANALYZE (ID: ${mainReport.id}, Date: ${new Date(mainReport.createdAt).toLocaleDateString()}) ---\n${mainReport.content}\n--- END PRIMARY INCIDENT ---`;
    
    const otherReportsContent = allReports
        .filter(r => r.id !== mainReport.id)
        .map(r => `--- SUPPORTING REPORT (ID: ${r.id}, Date: ${new Date(r.createdAt).toLocaleDateString()}) ---\n${r.content}\n--- END SUPPORTING REPORT ---`)
        .join('\n\n');

    const systemInstruction = SYSTEM_PROMPT_SINGLE_INCIDENT_ANALYSIS;
    const fullPrompt = `${systemInstruction}\n\n${formatUserProfileContext(userProfile)}\n\n## Incident Reports for Analysis:\n\n${mainReportContent}\n\n${otherReportsContent}`;

    const response = await ai.models.generateContent({
        model: 'gemini-2.5-pro', // Using a more powerful model for deep analysis
        contents: fullPrompt,
        config: {
            tools: [{googleSearch: {}}],
        }
    });
    
    const tokensUsed = response.usageMetadata?.totalTokenCount ?? 0;
    const sources = response.candidates?.[0]?.groundingMetadata?.groundingChunks || [];

    return { analysis: response.text, sources: sources, tokensUsed };
};


export const getLegalAssistantResponse = async (
    reports: Report[], 
    documents: StoredDocument[], 
    query: string, 
    userProfile: UserProfile | null,
    analysisContext: string | null
): Promise<{ response: LegalAssistantResponse & { sources?: any[] }; tokensUsed: number }> => {
    
    const reportsContent = reports.map(r => `--- REPORT (ID: ${r.id}, Date: ${new Date(r.createdAt).toLocaleDateString()}) ---\n${r.content}\n--- END REPORT ---`).join('\n\n');
    
    const textDocuments = documents.filter(d => d.mimeType.startsWith('text/'));
    const binaryDocuments = documents.filter(d => !d.mimeType.startsWith('text/'));

    const textDocumentsContent = textDocuments.length > 0 ? textDocuments
        .sort((a, b) => new Date(a.createdAt).getTime() - new Date(b.createdAt).getTime())
        .map(doc => {
            let contentSummary = '';
            try {
                const decodedText = decodeURIComponent(escape(atob(doc.data)));
                contentSummary = `Content Preview: ${decodedText.substring(0, 750)}...`;
            } catch (e) {
                contentSummary = 'Content could not be decoded.';
            }
            return `--- DOCUMENT ---\nFolder: ${doc.folder}\nName: ${doc.name}\nDate Created: ${new Date(doc.createdAt).toLocaleString()}\n${contentSummary}\n--- END DOCUMENT ---`;
        }).join('\n\n') : "No text documents available.";

    const binaryDocumentParts: Part[] = binaryDocuments.map(doc => ({
        inlineData: { data: doc.data, mimeType: doc.mimeType }
    }));
        
    const systemInstruction = `${SYSTEM_PROMPT_LEGAL_ASSISTANT}\n${formatUserProfileContext(userProfile)}`;
    
    try {
        let promptText = `${systemInstruction}\n\n## KNOWLEDGE BASE: Incident Reports\n\n${reportsContent}\n\n## KNOWLEDGE BASE: Generated & Text Documents\n\n${textDocumentsContent}`;

        if (analysisContext) {
            promptText += `\n\n## Forensic Incident Analysis (Primary Context):\n\n${analysisContext}`;
        }

        promptText += `\n\n## User's Question:\n\n${query}`;

        const textPart: Part = { text: promptText };

        const response = await ai.models.generateContent({
            model: 'gemini-2.5-flash',
            contents: { parts: [textPart, ...binaryDocumentParts] },
            config: {
                 tools: [{googleSearch: {}}],
            }
        });
    
        const tokensUsed = response.usageMetadata?.totalTokenCount ?? 0;
        const responseText = response.text;
        const firstBrace = responseText.indexOf('{');
        const lastBrace = responseText.lastIndexOf('}');

        if (firstBrace === -1 || lastBrace === -1 || lastBrace < firstBrace) {
            // If no JSON, assume it's a simple chat response.
             const finalResponse = { type: 'chat', content: responseText, sources: [] } as LegalAssistantResponse & { sources?: any[] };
            return { response: finalResponse, tokensUsed };
        }
        
        const jsonText = responseText.substring(firstBrace, lastBrace + 1);
        const parsedResponse = JSON.parse(jsonText);

        const sources = response.candidates?.[0]?.groundingMetadata?.groundingChunks || [];

        if (parsedResponse.type && parsedResponse.content) {
            const finalResponse = { ...parsedResponse, sources } as LegalAssistantResponse & { sources?: any[] };
            return { response: finalResponse, tokensUsed };
        }

        throw new Error("Invalid JSON structure from Legal Assistant API.");

    } catch (error) {
        console.error("Error getting or parsing legal assistant response:", error);
        const errorResponse: LegalAssistantResponse = {
            type: 'chat',
            content: "I'm sorry, an unexpected error occurred while processing your request. Please try again."
        };
        return { response: errorResponse, tokensUsed: 0 };
    }
};

export const getInitialLegalAnalysis = async (mainReport: Report, allReports: Report[], userProfile: UserProfile | null): Promise<{ response: LegalAssistantResponse & { sources?: any[] }; tokensUsed: number }> => {
    const mainReportContent = `--- PRIMARY INCIDENT TO ANALYZE (ID: ${mainReport.id}, Date: ${new Date(mainReport.createdAt).toLocaleDateString()}) ---\n${mainReport.content}\n--- END PRIMARY INCIDENT ---`;
    
    const otherReportsContent = allReports
        .filter(r => r.id !== mainReport.id)
        .map(r => `--- SUPPORTING REPORT (ID: ${r.id}, Date: ${new Date(r.createdAt).toLocaleDateString()}) ---\n${r.content}\n--- END SUPPORTING REPORT ---`)
        .join('\n\n');

    const systemInstruction = `${SYSTEM_PROMPT_LEGAL_ANALYSIS_SUGGESTION}\n${formatUserProfileContext(userProfile)}`;
    const fullPrompt = `${systemInstruction}\n\n## Incident Reports for Analysis:\n\n${mainReportContent}\n\n${otherReportsContent}`;
    
    try {
        const response = await ai.models.generateContent({
            model: 'gemini-2.5-flash',
            contents: fullPrompt,
            config: {
                tools: [{googleSearch: {}}],
            }
        });
    
        const tokensUsed = response.usageMetadata?.totalTokenCount ?? 0;
        const responseText = response.text;
        const firstBrace = responseText.indexOf('{');
        const lastBrace = responseText.lastIndexOf('}');

        if (firstBrace === -1 || lastBrace === -1 || lastBrace < firstBrace) {
            throw new Error("No valid JSON object found in the response from Legal Analysis API.");
        }
        
        const jsonText = responseText.substring(firstBrace, lastBrace + 1);
        const parsedResponse = JSON.parse(jsonText);
        const sources = response.candidates?.[0]?.groundingMetadata?.groundingChunks || [];

        if (parsedResponse.type === 'chat' && parsedResponse.content) {
            const finalResponse = { ...parsedResponse, sources } as LegalAssistantResponse & { sources?: any[] };
            return { response: finalResponse, tokensUsed };
        }

        throw new Error("Invalid JSON structure from Legal Analysis API.");

    } catch (error) {
        console.error("Error getting or parsing initial legal analysis:", error);
        const errorResponse: LegalAssistantResponse = {
            type: 'chat',
            content: "I'm sorry, an unexpected error occurred while analyzing the incident. Please try asking your question directly."
        };
        return { response: errorResponse, tokensUsed: 0 };
    }
};

export const analyzeDocument = async (
    fileData: string, 
    mimeType: string, 
    userProfile: UserProfile | null
): Promise<{ analysis: string; tokensUsed: number }> => {
    const systemInstruction = `${SYSTEM_PROMPT_DOCUMENT_ANALYSIS}\n${formatUserProfileContext(userProfile)}`;
    
    const documentPart = {
        inlineData: {
            data: fileData,
            mimeType: mimeType,
        },
    };

    const textPart = {
        text: "Please review and analyze this document according to your instructions."
    };

    try {
        const response = await ai.models.generateContent({
            model: 'gemini-2.5-flash',
            contents: { parts: [documentPart, textPart] },
            config: {
                systemInstruction: systemInstruction,
            }
        });
        
        const tokensUsed = response.usageMetadata?.totalTokenCount ?? 0;
        return { analysis: response.text, tokensUsed };
    } catch (error) {
        console.error("Error analyzing document:", error);
        return { analysis: "I'm sorry, an unexpected error occurred while analyzing the document. Please try again.", tokensUsed: 0 };
    }
};

export const redraftDocument = async (
    fileData: string,
    mimeType: string,
    analysisText: string,
    userProfile: UserProfile | null
): Promise<{ redraftedDoc: StructuredLegalDocument | null; tokensUsed: number }> => {
    const systemInstruction = `${SYSTEM_PROMPT_DOCUMENT_REDRAFT}\n${formatUserProfileContext(userProfile)}`;

    const documentPart = {
        inlineData: {
            data: fileData,
            mimeType: mimeType,
        },
    };

    const textPart = {
        text: `Here is the analysis of the document you are about to redraft. Please incorporate all these suggestions into the new version:\n\n--- ANALYSIS ---\n${analysisText}\n--- END ANALYSIS ---`
    };

    try {
        const response = await ai.models.generateContent({
            model: 'gemini-2.5-flash',
            contents: { parts: [documentPart, textPart] },
            config: {
                systemInstruction: systemInstruction,
                responseMimeType: "application/json",
                responseSchema: structuredLegalDocumentSchema,
            }
        });
        
        const tokensUsed = response.usageMetadata?.totalTokenCount ?? 0;
        const jsonText = response.text.trim();
        const redraftedDoc = JSON.parse(jsonText) as StructuredLegalDocument;
        return { redraftedDoc, tokensUsed };
    } catch (error) {
        console.error("Error redrafting document:", error);
        return { redraftedDoc: null, tokensUsed: 0 };
    }
};

export const generateEvidencePackage = async (
    selectedReports: Report[],
    selectedDocuments: StoredDocument[],
    userProfile: UserProfile | null,
    packageObjective: string,
): Promise<{ evidencePackage: StructuredLegalDocument | null; tokensUsed: number }> => {

    const reportsString = selectedReports
        .sort((a, b) => new Date(a.createdAt).getTime() - new Date(b.createdAt).getTime())
        .map(r => `
--- INCIDENT REPORT ---
ID: ${r.id}
Date of Incident: ${new Date(r.createdAt).toLocaleString()}
Category: ${r.category}
Tags: [${r.tags.join(', ')}]
Legal Context Note: ${r.legalContext || 'None provided.'}
Report Content:
${r.content}
--- END REPORT ---
`).join('\n\n');

    const documentsString = selectedDocuments.map(d => `
--- DOCUMENT ---
Name: ${d.name}
Date Uploaded: ${new Date(d.createdAt).toLocaleString()}
--- END DOCUMENT ---
`).join('\n\n');

    let systemInstruction = SYSTEM_PROMPT_EVIDENCE_PACKAGE.replace('{USER_PROFILE_CONTEXT}', formatUserProfileContext(userProfile));
    systemInstruction = systemInstruction.replace('{CURRENT_DATE}', new Date().toLocaleDateString('en-CA')); // YYYY-MM-DD format
    systemInstruction = systemInstruction.replace('{PACKAGE_OBJECTIVE}', packageObjective);

    const userPrompt = `Please generate the evidence package based on the following data.\n\n## SELECTED INCIDENT REPORTS ##\n\n${reportsString}\n\n## SELECTED DOCUMENTS ##\n\n${documentsString}`;

    try {
        const response = await ai.models.generateContent({
            model: 'gemini-2.5-pro', // Use pro model for high-stakes generation
            contents: userPrompt,
            config: {
                systemInstruction: systemInstruction,
                responseMimeType: "application/json",
                responseSchema: structuredLegalDocumentSchema,
            }
        });

        const tokensUsed = response.usageMetadata?.totalTokenCount ?? 0;
        const jsonText = response.text.trim();
        const evidencePackage = JSON.parse(jsonText) as StructuredLegalDocument;
        return { evidencePackage, tokensUsed };
    } catch (e) {
        console.error("Failed to generate evidence package:", e);
        return { evidencePackage: null, tokensUsed: 0 };
    }
};

// --- Agent Service (ai.live) ---

const countTextTokens = async (text: string, model: string): Promise<number> => {
    if (!text) return 0;
    try {
        const response = await ai.models.countTokens({ model, contents: [{ role: 'user', parts: [{ text }] }] });
        return response.totalTokens;
    } catch (e) {
        console.error("Token counting failed:", e);
        return Math.ceil(text.length / 4);
    }
};

const navigateToViewFunctionDeclaration: FunctionDeclaration = {
    name: 'navigateToView',
    parameters: {
        type: Type.OBJECT,
        description: 'Navigates the user to a specific view within the application.',
        properties: {
            view: {
                type: Type.STRING,
                description: `The view to navigate to. Must be one of: 'dashboard', 'timeline', 'new_report', 'patterns', 'insights', 'assistant', 'profile', 'documents', 'calendar'.`,
            },
        },
        required: ['view'],
    },
};

export const connectToAgent = (
    userProfile: UserProfile | null,
    callbacks: {
        onOpen: () => void;
        onMessage: (message: LiveServerMessage) => Promise<void>;
        onError: (error: ErrorEvent) => void;
        onClose: (event: CloseEvent) => void;
    }
): Promise<Session> => {
    const systemInstruction = SYSTEM_PROMPT_VOICE_AGENT.replace('{USER_PROFILE_CONTEXT}', formatUserProfileContext(userProfile));

    const sessionPromise = ai.live.connect({
        model: 'gemini-2.5-flash-native-audio-preview-09-2025',
        callbacks: {
            onopen: callbacks.onOpen,
            onmessage: callbacks.onMessage,
            onerror: callbacks.onError,
            onclose: callbacks.onClose,
        },
        config: {
            responseModalities: [Modality.AUDIO],
            speechConfig: {
                voiceConfig: { prebuiltVoiceConfig: { voiceName: 'Zephyr' } },
            },
            systemInstruction: systemInstruction,
            tools: [{ functionDeclarations: [navigateToViewFunctionDeclaration] }, { googleSearch: {} }],
            outputAudioTranscription: {},
            inputAudioTranscription: {},
        },
    });

    return sessionPromise;
};

export const countAgentTokens = async (text: string): Promise<number> => {
    return countTextTokens(text, 'gemini-2.5-flash-native-audio-preview-09-2025');
};


// Audio Utilities
export function createPcmBlob(data: Float32Array): Blob {
    const l = data.length;
    const int16 = new Int16Array(l);
    for (let i = 0; i < l; i++) {
        int16[i] = data[i] * 32768;
    }
    return {
        data: encode(new Uint8Array(int16.buffer)),
        mimeType: 'audio/pcm;rate=16000',
    };
}

export function encode(bytes: Uint8Array): string {
    let binary = '';
    const len = bytes.byteLength;
    for (let i = 0; i < len; i++) {
        binary += String.fromCharCode(bytes[i]);
    }
    return btoa(binary);
}

export function decode(base64: string): Uint8Array {
    const binaryString = atob(base64);
    const len = binaryString.length;
    const bytes = new Uint8Array(len);
    for (let i = 0; i < len; i++) {
        bytes[i] = binaryString.charCodeAt(i);
    }
    return bytes;
}

export async function decodeAudioData(
    data: Uint8Array,
    ctx: AudioContext,
    sampleRate: number,
    numChannels: number,
): Promise<AudioBuffer> {
    const dataInt16 = new Int16Array(data.buffer);
    const frameCount = dataInt16.length / numChannels;
    const buffer = ctx.createBuffer(numChannels, frameCount, sampleRate);

    for (let channel = 0; channel < numChannels; channel++) {
        const channelData = buffer.getChannelData(channel);
        for (let i = 0; i < frameCount; i++) {
            channelData[i] = dataInt16[i * numChannels + channel] / 32768.0;
        }
    }
    return buffer;
}
